{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "import loader\n",
    "from qLearningNet import *\n",
    "import time\n",
    "from AIModels import *\n",
    "from replayMemory import *\n",
    "from g2048 import *\n",
    "import os\n",
    "\n",
    "\n",
    "MOVES = [0, 1, 2, 3]\n",
    "\n",
    "FILENAME = \"saved_parameters\"\n",
    "INPUT_SIZE = 16\n",
    "HIDDEN_SIZE = 256\n",
    "\n",
    "\n",
    "def testNet(filename=None, net=None):\n",
    "    game = G2048(save_game=False)\n",
    "    if filename is not None:\n",
    "        ai = QLearningNetAI(game, filename=filename)\n",
    "    elif net is not None:\n",
    "        ai = QLearningNetAI(game, net=net)\n",
    "    scores, move_count, highs = AIModel.test_ai(ai, 400, verbose=False)\n",
    "    return move_count, np.mean(scores), np.mean(highs)\n",
    "\n",
    "\n",
    "test_q_set = loader.Loader.get_random_states(G2048(), 100, input_size=INPUT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, data_loaders, optimizer, num_epochs=500, log_every=100, verbose=True, batch_size=100, \\\n",
    "          use_memory=True, gamma=0.8, filename_prefix=\"\"):\n",
    "    replays = ReplayMemory(10**5, entry_len=34)\n",
    "        \n",
    "    results = []\n",
    "    losses = []\n",
    "    q_values = []\n",
    "    \n",
    "    epoch = 0\n",
    "    if verbose:\n",
    "        print u'Training the model!'\n",
    "        print u'Interrupt at any time to get current model'\n",
    "    try:\n",
    "        while epoch < num_epochs:\n",
    "            epoch += 1\n",
    "            new_data = data_loaders.get(model, batch_size)\n",
    "            if use_memory:\n",
    "                replays.add(new_data)\n",
    "                x = replays.choose(batch_size)\n",
    "            else:\n",
    "                x = new_data\n",
    "            \n",
    "            future = x[:, (INPUT_SIZE+2):]\n",
    "            future_scores = model.Q(future)\n",
    "            for i, row in enumerate(future):\n",
    "                game = G2048(save_game=False, data=row.tolist())\n",
    "                for j, move in enumerate(MoveEnum):\n",
    "                    if not game.canMove(move):\n",
    "                        future_scores[i, j] = float('-inf')\n",
    "                if not game.getPossibleMoves():\n",
    "                    future_scores[i:,:] = np.full((1,4), x[i, (INPUT_SIZE+1)])\n",
    "                \n",
    "            y = x[:, (INPUT_SIZE+1)] + gamma * np.max(future_scores, axis=1)\n",
    "            xx = x[:, :INPUT_SIZE]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            i = np.asarray(np.vstack((np.arange(0,batch_size),x[:,INPUT_SIZE])),int)\n",
    "            \n",
    "            i = torch.LongTensor(i)\n",
    "            out = model.Q(xx, as_variable=True)[i[0],i[1]]\n",
    "            loss = model.loss(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if epoch % log_every == 0 and verbose:\n",
    "                print u\"Minibatch {0: >6}  | loss {1: >15.12f} \".format(epoch, loss.data[0])\n",
    "                result = testNet(net=model)\n",
    "                print u\"The average score was {}\".format(result[1])\n",
    "                results += [result[1]]\n",
    "                losses += [loss.data.numpy()]\n",
    "                q_val = model.Q(test_q_set)\n",
    "                q_values += [np.mean(np.max(q_val, axis=1))]\n",
    "                print u\"The average Q function value was {}\".format(q_values[-1])\n",
    "                \n",
    "            if epoch % (log_every * 20) == 0:\n",
    "                result = testNet(net=model)\n",
    "                filename = filename_prefix + FILENAME +'{}_{}'.format(epoch, int(result[1]))\n",
    "                model.save_parameters(filename)\n",
    "                \n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    result = testNet(net=model)\n",
    "    filename = filename_prefix + FILENAME +'{}_{}'.format(epoch, int(result[1]))\n",
    "    model.save_parameters(filename)\n",
    "    return results, losses, q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in np.logspace(-4.0,4.0,12):\n",
    "    path=\"result2048/results_lr_{:.5f}/\".format(lr)\n",
    "    print \"Saving to\",path\n",
    "    try: \n",
    "        os.makedirs(path)\n",
    "    except OSError:\n",
    "        if not os.path.isdir(path):\n",
    "            raise\n",
    "    q_learning_net = QLearningNet(input_size=INPUT_SIZE)\n",
    "    for p in q_learning_net.network.parameters():\n",
    "        p.requires_grad = True\n",
    "    optimizer = torch.optim.Adam(q_learning_net.network.parameters(), lr=lr)\n",
    "    data_loader = loader.Loader(game=G2048())\n",
    "    scores, loses, q_values = train(q_learning_net, data_loader, optimizer, num_epochs=10000,filename_prefix=path)\n",
    "    print \"Learning for\",lr,\"done. (#learningdone)\"\n",
    "    np.savetxt(path+'scores', scores)\n",
    "    np.savetxt(path+'loses', loses)\n",
    "    np.savetxt(path+'qvalues', q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_result(path, title):\n",
    "    scores = np.loadtxt(path+'scores')\n",
    "    q_values = np.loadtxt(path+'qvalues')\n",
    "    loses = np.loadtxt(path+'loses')\n",
    "    figure(figsize=(16,10))\n",
    "    subplot(1,3,1)\n",
    "    plot(range(100,len(scores)*100+1, 100), scores, marker='o')\n",
    "    xlabel('Number of epochs')\n",
    "    ylabel('Average score')\n",
    "    subplot(1,3,2)\n",
    "    plot(range(100,len(scores)*100+1, 100), np.log(loses), marker='o')\n",
    "    xlabel('Number of epochs')\n",
    "    ylabel('Loss')\n",
    "    subplot(1,3,3)\n",
    "    plot(range(100,len(scores)*100+1, 100), q_values, marker='o')\n",
    "    xlabel('Number of epochs')\n",
    "    ylabel('Q values')\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paths = []\n",
    "for lr in np.logspace(-4.0,4.0,12):\n",
    "    paths += [\"result2048/results_lr_{:.5f}/\".format(lr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    plot_result(path, \"Results for learning rate {:.5f}\".format(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "game = G2048(save_game=False)\n",
    "ai = RandomAI(game)\n",
    "scores, move_count, highs = AIModel.test_ai(ai, 1000, verbose=False)\n",
    "print move_count\n",
    "print np.mean(scores), np.mean(highs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
