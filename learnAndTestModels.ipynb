{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "import loader\n",
    "from threes import *\n",
    "from g2048 import *\n",
    "from easyGame import *\n",
    "from qLearningNet import *\n",
    "import time\n",
    "from AIModels import *\n",
    "from replayMemory import *\n",
    "import os\n",
    "\n",
    "\n",
    "PLAYED_GAME = Threes\n",
    "MOVES = [0, 1, 2, 3]\n",
    "\n",
    "FILENAME = \"saved_parameters\"\n",
    "INPUT_SIZE = 19\n",
    "ENTRY_LEN = 40\n",
    "NUM_EPOCH = 500\n",
    "\n",
    "def testNet(filename=None, net=None):\n",
    "    game = PLAYED_GAME(save_game=False)\n",
    "    if filename is not None:\n",
    "        ai = QLearningNetAI(game, filename=filename)\n",
    "    elif net is not None:\n",
    "        ai = QLearningNetAI(game, net=net)\n",
    "    scores, move_count, highs = AIModel.test_ai(ai, 400, verbose=False)\n",
    "    return move_count, np.mean(scores), np.mean(highs)\n",
    "\n",
    "\n",
    "test_q_set = loader.Loader.get_random_states(PLAYED_GAME(), 100, input_size=INPUT_SIZE)\n",
    "# uczyc jednak dobrymi przebiegami\n",
    "# probowav 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, data_loaders, optimizer, num_epochs=500, log_every=100, verbose=True, batch_size=100, \\\n",
    "          use_memory=True, gamma=0.8, filename_prefix=\"\"):\n",
    "    replays = ReplayMemory(10**5, entry_len=ENTRY_LEN)\n",
    "        \n",
    "    results = []\n",
    "    losses = []\n",
    "    q_values = []\n",
    "    \n",
    "    epoch = 0\n",
    "    if verbose:\n",
    "        print u'Training the model!'\n",
    "        print u'Interrupt at any time to get current model'\n",
    "    try:\n",
    "        while epoch < num_epochs:\n",
    "            epoch += 1\n",
    "            new_data = data_loaders.get(model, batch_size)\n",
    "            if use_memory:\n",
    "                replays.add(new_data)\n",
    "                x = replays.choose(batch_size)\n",
    "            else:\n",
    "                x = new_data\n",
    "\n",
    "            future = x[:, (INPUT_SIZE+2):]\n",
    "            future_scores = model.Q(future)\n",
    "            for i, row in enumerate(future):\n",
    "                game = PLAYED_GAME(save_game=False, data=row.tolist())\n",
    "                for j, move in enumerate(MoveEnum):\n",
    "                    if not game.canMove(move):\n",
    "                        future_scores[i, j] = float('-inf')\n",
    "                if not game.getPossibleMoves():\n",
    "                    future_scores[i,:] = np.full((1,4), x[i, (INPUT_SIZE+1)])\n",
    "                \n",
    "            y = x[:, (INPUT_SIZE+1)] + gamma * np.max(future_scores, axis=1)\n",
    "            xx = x[:, :INPUT_SIZE]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            i = np.asarray(np.vstack((np.arange(0,batch_size),x[:,INPUT_SIZE])),int)\n",
    "            \n",
    "            i = torch.LongTensor(i)\n",
    "            out = model.Q(xx, as_variable=True)[i[0],i[1]]\n",
    "            loss = model.loss(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if epoch % log_every == 0 and verbose:\n",
    "                print u\"Minibatch {0: >6}  | loss {1: >15.12f} \".format(epoch, loss.data[0])\n",
    "                result = testNet(net=model)\n",
    "                print u\"The average score was {}\".format(result[1])\n",
    "                results += [result[1]]\n",
    "                losses += [loss.data.numpy()]\n",
    "                q_val = model.Q(test_q_set)\n",
    "                q_values += [np.mean(np.max(q_val, axis=1))]\n",
    "                print u\"The average Q-value was {}\".format(q_values[-1])\n",
    "                \n",
    "            if epoch % (log_every * 20) == 0:\n",
    "                result = testNet(net=model)\n",
    "                filename = filename_prefix + FILENAME +'{}_{}'.format(epoch, int(result[1]))\n",
    "                model.save_parameters(filename)\n",
    "                \n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    result = testNet(net=model)\n",
    "    filename = filename_prefix + FILENAME +'{}_{}'.format(epoch, int(result[1]))\n",
    "    model.save_parameters(filename)\n",
    "    return results, losses, q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to results_lr_0.00010/\n",
      "Training the model!\n",
      "Interrupt at any time to get current model\n",
      "Minibatch    100  | loss  0.000767198741 \n",
      "The average score was 260.1075\n",
      "The average Q-value was 0.0318689979613\n",
      "Minibatch    200  | loss  0.000470132305 \n",
      "The average score was 275.5425\n",
      "The average Q-value was 0.0312559008598\n",
      "Minibatch    300  | loss  0.000396209594 \n",
      "The average score was 260.49\n",
      "The average Q-value was 0.029283253476\n",
      "Minibatch    400  | loss  0.000619669911 \n",
      "The average score was 249.3975\n",
      "The average Q-value was 0.0276089254767\n"
     ]
    }
   ],
   "source": [
    "for lr in np.logspace(-4.0,4.0,12):\n",
    "    path=\"results_lr_{:.5f}/\".format(lr)\n",
    "    print \"Saving to\",path\n",
    "    try: \n",
    "        os.makedirs(path)\n",
    "    except OSError:\n",
    "        if not os.path.isdir(path):\n",
    "            raise\n",
    "    q_learning_net = QLearningNet(input_size = INPUT_SIZE)\n",
    "    for p in q_learning_net.network.parameters():\n",
    "        p.requires_grad = True\n",
    "    optimizer = torch.optim.Adam(q_learning_net.network.parameters(), lr=lr)\n",
    "    data_loader = loader.Loader(game = PLAYED_GAME())\n",
    "    scores, loses, q_values = train(q_learning_net, data_loader, optimizer, num_epochs=NUM_EPOCH,filename_prefix=path)\n",
    "    print \"Learning for\",lr,\"done. (#learningdone)\"\n",
    "    np.savetxt(path+'scores', scores)\n",
    "    np.savetxt(path+'loses', loses)\n",
    "    np.savetxt(path+'qvalues', q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning for 1.0 done. (#learningdone)\n"
     ]
    }
   ],
   "source": [
    "for lr in [1.0]:\n",
    "    path=\"results_lr_{:.5f}/\".format(lr)\n",
    "    print \"Saving to\",path\n",
    "    try: \n",
    "        os.makedirs(path)\n",
    "    except OSError:\n",
    "        if not os.path.isdir(path):\n",
    "            raise\n",
    "    q_learning_net = QLearningNet()\n",
    "    for p in q_learning_net.network.parameters():\n",
    "        p.requires_grad = True\n",
    "    optimizer = torch.optim.Adam(q_learning_net.network.parameters(), lr=lr)\n",
    "    data_loader = loader.Loader()\n",
    "    scores, loses, q_values = train(q_learning_net, data_loader, optimizer, num_epochs=NUM_EPOCH,filename_prefix=path)\n",
    "    print \"Learning for\",lr,\"done. (#learningdone)\"\n",
    "    np.savetxt(path+'scores', scores)\n",
    "    np.savetxt(path+'loses', loses)\n",
    "    np.savetxt(path+'qvalues', q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figure(figsize=(16,10))\n",
    "subplot(1,3,1)\n",
    "plot(range(100,len(scores)*100+1, 100), scores, marker='o')\n",
    "xlabel('Number of epochs')\n",
    "ylabel('Average score')\n",
    "subplot(1,3,2)\n",
    "plot(range(100,len(scores)*100+1, 100), np.log(loses), marker='o')\n",
    "xlabel('Number of epochs')\n",
    "ylabel('Loss')\n",
    "subplot(1,3,3)\n",
    "plot(range(100,len(scores)*100+1, 100), q_values, marker='o')\n",
    "xlabel('Number of epochs')\n",
    "ylabel('Q values')\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for lr in np.logspace(-2.0,4.0,8):\n",
    "    for wd in np.logspace(-6.0, -1.0, 5):\n",
    "        path=\"results_lr_{:.5f}_wd_{:.6f}/\".format(lr, wd)\n",
    "        print \"Saving to\",path\n",
    "        try: \n",
    "            os.makedirs(path)\n",
    "        except OSError:\n",
    "            if not os.path.isdir(path):\n",
    "                raise\n",
    "        q_learning_net = QLearningNet()\n",
    "        for p in q_learning_net.network.parameters():\n",
    "            p.requires_grad = True\n",
    "        optimizer = torch.optim.Adam(q_learning_net.network.parameters(), lr=lr)\n",
    "        data_loader = loader.Loader()\n",
    "        scores, loses, q_values = train(q_learning_net, data_loader, optimizer, num_epochs=10000,filename_prefix=path)\n",
    "        print \"Learning for\",lr,\"done. (#learningdone)\"\n",
    "        np.savetxt(path+'scores', scores)\n",
    "        np.savetxt(path+'loses', loses)\n",
    "        np.savetxt(path+'qvalues', q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_result(path, title):\n",
    "    scores = np.loadtxt(path+'scores')\n",
    "    q_values = np.loadtxt(path+'qvalues')\n",
    "    loses = np.loadtxt(path+'loses')\n",
    "    figure(figsize=(16,10))\n",
    "    suptitle(title)\n",
    "    subplot(1,3,1)\n",
    "    plot(range(100,len(scores)*100+1, 100), scores, marker='o')\n",
    "    xlabel('Number of epochs')\n",
    "    ylabel('Average score')\n",
    "    subplot(1,3,2)\n",
    "    plot(range(100,len(scores)*100+1, 100), np.log(loses), marker='o')\n",
    "    xlabel('Number of epochs')\n",
    "    ylabel('Loss')\n",
    "    subplot(1,3,3)\n",
    "    plot(range(100,len(scores)*100+1, 100), q_values, marker='o')\n",
    "    xlabel('Number of epochs')\n",
    "    ylabel('Q values')\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paths = []\n",
    "for lr in np.logspace(-2.0,4.0,8):\n",
    "    for wd in np.logspace(-6.0, -1.0, 5):\n",
    "        paths += [\"results_lr_{:.5f}_wd_{:.6f}/\".format(lr, wd)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    plot_result(path, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "game = PLAYED_GAME(save_game=False)\n",
    "ai = QLearningNetAI(game, net=q_learning_net)#filename='results_lr_1.00000/saved_parameters1400_474')\n",
    "scores, move_count, highs = AIModel.test_ai(ai, 1, verbose=True)\n",
    "print move_count\n",
    "print np.mean(scores), np.mean(highs)\n",
    "for p in ai.ai.network.parameters():\n",
    "    print p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = np.random.random(19)\n",
    "print r\n",
    "print ai.ai.Q(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W1, b1, W2, b2 = ai.ai.network.parameters()\n",
    "W1 = W1.data.numpy()\n",
    "b1 = b1.data.numpy()\n",
    "W2 = W2.data.numpy()\n",
    "b2 = b2.data.numpy()\n",
    "x = np.dot(W1, r) + b1\n",
    "y = np.tanh(x)\n",
    "z = np.dot(W2,y)+b2\n",
    "print x\n",
    "print sign(y), y.sum()\n",
    "print z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "game = PLAYED_GAME(save_game=False)\n",
    "ai = RandomAI(game)\n",
    "scores, move_count, highs = AIModel.test_ai(ai, 1000, verbose=False)\n",
    "print move_count\n",
    "print np.mean(scores), np.mean(highs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "game = PLAYED_GAME(save_game=False)\n",
    "ai = MiniMaxAI(game)\n",
    "scores, move_count, highs = AIModel.test_ai(ai, 10, verbose=False)\n",
    "print move_count\n",
    "print np.mean(scores), np.mean(highs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, data_loaders, optimizer, num_epochs=500, log_every=100, verbose=True, batch_size=100, \\\n",
    "          use_memory=True, gamma=0.8, filename_prefix=\"\"):\n",
    "    replays = ReplayMemory(10**5, entry_len=ENTRY_LEN)\n",
    "        \n",
    "    results = []\n",
    "    losses = []\n",
    "    q_values = []\n",
    "    \n",
    "    epoch = 0\n",
    "    if verbose:\n",
    "        print u'Training the model!'\n",
    "        print u'Interrupt at any time to get current model'\n",
    "    try:\n",
    "        while epoch < num_epochs:\n",
    "            epoch += 1\n",
    "            \n",
    "            new_data = data_loaders.get(model, batch_size)\n",
    "            if use_memory:\n",
    "                replays.add(new_data)\n",
    "                x = replays.choose(batch_size)\n",
    "            else:\n",
    "                x = new_data\n",
    "            \n",
    "            future = x[:, (INPUT_SIZE+2):]\n",
    "            future_scores = model.Q(future)\n",
    "            for i, row in enumerate(future):\n",
    "                game = PLAYED_GAME(save_game=False, data=row.tolist())\n",
    "                for j, move in enumerate(MoveEnum):\n",
    "                    if not game.canMove(move):\n",
    "                        future_scores[i, j] = float('-inf')\n",
    "                if not game.getPossibleMoves():\n",
    "                    future_scores[i,:] = np.full((1,4), x[i, (INPUT_SIZE+1)])\n",
    "                \n",
    "            y = x[:, (INPUT_SIZE+1)] + gamma * np.max(future_scores, axis=1)\n",
    "            xx = x[:, :INPUT_SIZE]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            i = np.asarray(np.vstack((np.arange(0,batch_size),x[:,INPUT_SIZE])),int)\n",
    "            \n",
    "            i = torch.LongTensor(i)\n",
    "            out = model.Q(xx, as_variable=True)[i[0],i[1]]\n",
    "            loss = model.loss(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if epoch % log_every == 0 and verbose:\n",
    "                print u\"Minibatch {0: >6}  | loss {1: >15.12f} \".format(epoch, loss.data[0])\n",
    "                result = testNet(net=model)\n",
    "                print u\"The average score was {}\".format(result[1])\n",
    "                results += [result[1]]\n",
    "                losses += [loss.data.numpy()]\n",
    "                q_val = model.Q(test_q_set)\n",
    "                q_values += [np.mean(np.max(q_val, axis=1))]\n",
    "                print u\"The average Q function value was {}\".format(q_values[-1])\n",
    "                \n",
    "            if epoch % (log_every * 20) == 0:\n",
    "                result = testNet(net=model)\n",
    "                filename = filename_prefix + FILENAME +'{}_{}'.format(epoch, int(result[1]))\n",
    "                model.save_parameters(filename)\n",
    "                \n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    result = testNet(net=model)\n",
    "    filename = filename_prefix + FILENAME +'{}_{}'.format(epoch, int(result[1]))\n",
    "    model.save_parameters(filename)\n",
    "    return results, losses, q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
